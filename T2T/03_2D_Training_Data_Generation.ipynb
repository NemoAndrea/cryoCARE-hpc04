{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Generation - 2D slices\n",
    "\n",
    "In this step we will extract the training/validation data from the even/odd tomograms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_train_data import *\n",
    "\n",
    "import mrcfile\n",
    "from os.path import join, isdir\n",
    "from os import makedirs\n",
    "from glob import glob\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two tomograms \n",
    "even = mrcfile.open(glob('frames/even/tomogram/half-tomo.rec')[0]).data\n",
    "odd = mrcfile.open(glob('frames/odd/tomogram/half-tomo.rec')[0]).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we compute the mean and standard deviation which is needed to\n",
    "# normalize the inputs for the network.\n",
    "mean, std = compute_mean_std(np.stack((even, odd)))\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train_data directory\n",
    "if not isdir('train_data/'):\n",
    "    makedirs('train_data/')\n",
    "# We save mean and standard deviation since it is needed during prediction.\n",
    "np.savez('train_data/mean_std.npz', mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n",
    "In some cases you want to sample training/validation data not from the whole tomogram in that case you can create a mask from which the samples will be drawn. \n",
    "\n",
    "If you want to just include everything, don't change anything in the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample XY plane of tomogram \n",
    "mask = np.ones(even.shape[1:3], dtype=np.int8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Coordinates & Extract Patches\n",
    "\n",
    "With our mask we will now sample coordinates. We sample only 'planes' of the reconstruction that match most closely the original projections.\n",
    "\n",
    "So we pick random 2D patches from a random z slice of the reconstructed tomograms. This is different from the standard T2T approach described in the original publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we use the sampled coordinates to extract the train- and validation-patches.\n",
    "\n",
    "num_slices = even.shape[0] # number of slices in 'z' of tomogram\n",
    "for i in range(num_slices):\n",
    "    print('Sampling from z slice: ' + str(i))\n",
    "    train_coords, val_coords = sample_coordinates_2D(np.copy(mask), num_train_vols=10, num_val_vols=1, vol_dims=(128,128))\n",
    "   \n",
    "    Xtemp, Ytemp, X_valtemp, Y_valtemp = extract_samples(even[i,:,:], odd[i,:,:], train_coords, val_coords, mean, std)\n",
    "    if i==0:\n",
    "        X = Xtemp\n",
    "        Y = Ytemp\n",
    "        X_val = X_valtemp\n",
    "        Y_val = Y_valtemp\n",
    "    else:\n",
    "        X = np.concatenate((X,Xtemp), axis = 0)\n",
    "        Y = np.concatenate((Y,Ytemp), axis = 0)\n",
    "        X_val = np.concatenate((X_val,X_valtemp), axis = 0)\n",
    "        Y_val = np.concatenate((Y_val,Y_valtemp), axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what fraction of tomogram volume do we cover with this num_train_vols (keep it below 100%) ?\n",
    "tomo_voxels = np.shape(even)[0]*np.shape(even)[1]*np.shape(even)[2]\n",
    "sampled_voxels = 128*128*np.shape(even)[0]*10\n",
    "print('sampled percentage is: ' + str(sampled_voxels/tomo_voxels*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(X[0,:,:,0], cmap='gray')\n",
    "plt.title('X');\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(Y[0,:,:,0], cmap='gray')\n",
    "plt.title('Y');\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(X_val[0,:,:,0], cmap='gray')\n",
    "plt.title('X_val');\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(Y_val[0,:,:,0], cmap='gray')\n",
    "plt.title('Y_val');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train-/Validation-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('train_data/train_data.npz', X=X, Y=Y, X_val=X_val, Y_val=Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
