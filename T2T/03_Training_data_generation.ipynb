{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Generation \n",
    "\n",
    "In this step we will extract the training/validation data from the even/odd tomograms. You will have the option to train a network on 3D or 2D data. 3D is the standard method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_train_data import *\n",
    "\n",
    "import mrcfile\n",
    "from os.path import join, isdir\n",
    "from os import makedirs\n",
    "from glob import glob\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we first load the tomograms. The default tomogram name is `half-tomo.rec` but if you used SIRT the name will be something like `half-tomo_SIRT_iter_<numiterations>.rec`. So for SIRT, you will have to edit the filename below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two tomograms \n",
    "even = mrcfile.open(glob('frames/even/tomogram/half-tomo.rec')[0]).data\n",
    "odd = mrcfile.open(glob('frames/odd/tomogram/half-tomo.rec')[0]).data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = compute_mean_std(np.stack((even, odd)))\n",
    "\n",
    "# Create the train_data directory\n",
    "if not isdir('train_data/'):\n",
    "    makedirs('train_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n",
    "In some cases you might not want to draw training samples from every part of the tomogram. In this case you can specify this in the mask, which which specifies which area training data is sampled from. You can specify a rectangle that will be used to sample from (seen from the default view; optical axis). \n",
    "\n",
    "Unless you really have good reason to not sample from the whole tomogram, just leave the line below as is, run it, and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones(even.shape, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D or 2D?\n",
    "\n",
    "You can use a 2D or 3D network for denoising. 3D is generally better for practical purposes and should be your default option. You can use the 2D option if you used SIRT in the reconstruction. 2D can produce less distorted tomograms when viewed in a volume viewer like UCSF Chimera.\n",
    "\n",
    "Set the type below to one of the options below:\n",
    "* `type2D`\n",
    "* `type3D` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change line below if you want to use 2D\n",
    "dimensionality = project.type3D\n",
    "\n",
    "print('Using a ' + str(dimensionality.value) + ' network for the remainder of this project.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Coordinates\n",
    "\n",
    "With our mask we will now sample coordinates for the train and validation volumes (3D) or slices (2D). \n",
    "\n",
    "The method `sample_coordinates` will return two lists with coordinates of volumes or slices. The train and validation volumes will not overlap. It will take a few minutes.\n",
    "\n",
    "Default `sample length` for `type3D` is 64 while it is 128 for `type2D` \n",
    "\n",
    "A good number of sample points is 1200 for `type3D` and for `type2D` 40 is a good number (as it will be multiplied by the z-height of the tomogram). Number of validation samples are best left at about 1/10 of number of training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coords, val_coords = sample_coordinates(mask,\n",
    "                                              num_train_samples=1200,\n",
    "                                              num_val_samples=120,\n",
    "                                              sample_length=64,\n",
    "                                              net_dim = dimensionality.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Volumes\n",
    "Now we use our sampled coordinates to extract volumes that can be used as training data for the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we use the sampled coordinates to extract the train- and validation-volumes.\n",
    "X, Y, X_val, Y_val = extract_samples(even, odd, train_coords, val_coords, mean, std, net_dim = dimensionality.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random sample to show (re-run this cell to see different samples!)\n",
    "plot_train_data(X, Y, X_val, Y_val, net_dim = dimensionality.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train-/Validation-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('train_data/train_data.npz', X=X, Y=Y, X_val=X_val, Y_val=Y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
